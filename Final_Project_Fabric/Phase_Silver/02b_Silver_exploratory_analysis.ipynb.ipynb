{"cells":[{"cell_type":"code","source":["\"\"\"\n","SILVER LAYER EXPLORATORY ANALYSIS\n","Understanding data structure and analytical capabilities\n","\"\"\"\n","\n","print(\"=\"*80)\n","print(\"üîç SILVER LAYER EXPLORATORY ANALYSIS\")\n","print(\"=\"*80)\n","\n","from pyspark.sql.functions import *\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","print(f\"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","\n","# ============================================================================\n","# 1. UNDERSTAND EACH TABLE STRUCTURE\n","# ============================================================================\n","print(\"\\n1Ô∏è‚É£ TABLE STRUCTURE ANALYSIS\")\n","print(\"=\"*80)\n","\n","# List all active tables (exclude backups)\n","active_tables = [\n","    # Core fact tables\n","    \"silver_taxi_clean\",\n","    \"silver_taxi_daily\",\n","    \"silver_air_quality_daily\",\n","    \n","    # Dimension tables\n","    \"dim_date_clean\",\n","    \"dim_zones\",\n","    \n","    # Economic data\n","    \"silver_fx_clean\",\n","    \"silver_gdp_clean\",\n","    \n","    # Detailed pollutant data\n","    \"silver_pm25_std\",\n","    \"silver_no2_std\",\n","    \"silver_o3_std\",\n","    \"silver_pm10_std\"\n","]\n","\n","print(f\"Analyzing {len(active_tables)} active tables...\")\n","\n","# Dictionary to store date info for later analysis\n","date_info = {}\n","\n","for table_name in active_tables:\n","    print(f\"\\nüìä {table_name}:\")\n","    try:\n","        df = spark.table(table_name)\n","        \n","        # Basic info\n","        row_count = df.count()\n","        print(f\"   Rows: {row_count:,}\")\n","        print(f\"   Columns: {len(df.columns)}\")\n","        \n","        # Show column names and sample data types\n","        print(f\"   First 5 columns: {df.columns[:5]}\")\n","        \n","        # Date columns\n","        date_cols = [c for c in df.columns if \"date\" in c.lower() or \"time\" in c.lower()]\n","        if date_cols:\n","            print(f\"   Date columns: {date_cols}\")\n","            # Store date info for later analysis\n","            for date_col in date_cols[:1]:  # Check first date column\n","                try:\n","                    dates = df.select(min(date_col), max(date_col)).collect()[0]\n","                    min_date = dates[0]\n","                    max_date = dates[1]\n","                    print(f\"   Date range: {min_date} to {max_date}\")\n","                    \n","                    # Store for later use\n","                    date_info[table_name] = {\n","                        \"min_date\": min_date,\n","                        \"max_date\": max_date,\n","                        \"date_column\": date_col\n","                    }\n","                except Exception as e:\n","                    print(f\"   Error getting date range: {str(e)[:100]}\")\n","        \n","        # Numeric columns\n","        numeric_cols = []\n","        for col_name in df.columns:\n","            try:\n","                # Try to check if numeric\n","                sample_df = df.select(col_name).limit(1)\n","                sample_row = sample_df.collect()[0]\n","                sample_value = sample_row[0]\n","                if isinstance(sample_value, (int, float)):\n","                    numeric_cols.append(col_name)\n","            except:\n","                pass\n","        \n","        if numeric_cols:\n","            print(f\"   Numeric columns: {len(numeric_cols)} (e.g., {numeric_cols[:3]})\")\n","            \n","        # Show small sample\n","        print(f\"   Sample data:\")\n","        df.limit(3).show(vertical=True, truncate=50)\n","        \n","    except Exception as e:\n","        print(f\"   ‚ùå Error: {str(e)[:100]}\")\n","\n","# ============================================================================\n","# 2. CHECK DATE ALIGNMENT BETWEEN TABLES (FIXED VERSION)\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"2Ô∏è‚É£ DATE ALIGNMENT ANALYSIS\")\n","print(\"=\"*80)\n","\n","# Find overlapping periods (FIXED VERSION)\n","print(\"\\nüîó POTENTIAL JOIN POINTS:\")\n","\n","# Check taxi vs air quality\n","if \"silver_taxi_daily\" in date_info and \"silver_air_quality_daily\" in date_info:\n","    taxi_info = date_info[\"silver_taxi_daily\"]\n","    air_info = date_info[\"silver_air_quality_daily\"]\n","    \n","    # Extract dates as Python datetime objects\n","    try:\n","        # Convert to string for comparison if needed\n","        taxi_start = str(taxi_info[\"min_date\"])\n","        taxi_end = str(taxi_info[\"max_date\"])\n","        air_start = str(air_info[\"min_date\"])\n","        air_end = str(air_info[\"max_date\"])\n","        \n","        print(f\"   Taxi dates: {taxi_start} to {taxi_end}\")\n","        print(f\"   Air dates: {air_start} to {air_end}\")\n","        \n","        # Calculate overlap using SQL instead\n","        try:\n","            taxi_dates = spark.table(\"silver_taxi_daily\").select(\"pickup_date\").distinct()\n","            air_dates = spark.table(\"silver_air_quality_daily\").select(\"measurement_date\").distinct()\n","            \n","            overlapping_dates = taxi_dates.join(\n","                air_dates, \n","                taxi_dates.pickup_date == air_dates.measurement_date\n","            )\n","            overlap_count = overlapping_dates.count()\n","            \n","            if overlap_count > 0:\n","                # Get actual overlap dates\n","                overlap_min_max = overlapping_dates.select(\n","                    min(\"pickup_date\").alias(\"min_overlap\"),\n","                    max(\"pickup_date\").alias(\"max_overlap\")\n","                ).collect()[0]\n","                \n","                print(f\"   ‚úÖ Taxi ‚Üî Air Quality overlap: {overlap_min_max['min_overlap']} to {overlap_min_max['max_overlap']}\")\n","                print(f\"   Days with BOTH taxi and air data: {overlap_count}\")\n","                \n","                print(f\"   Sample overlapping dates:\")\n","                overlapping_dates.limit(5).show()\n","            else:\n","                print(f\"   ‚ö†Ô∏è  NO DATE OVERLAP between taxi and air quality data\")\n","                \n","        except Exception as e:\n","            print(f\"   Error analyzing overlap: {str(e)[:100]}\")\n","            \n","    except Exception as e:\n","        print(f\"   Error processing dates: {str(e)[:100]}\")\n","\n","# Check FX overlap with taxi\n","print(\"\\nüí± FX ‚Üî Taxi Date Alignment:\")\n","if \"silver_taxi_daily\" in date_info and \"silver_fx_clean\" in date_info:\n","    fx_info = date_info[\"silver_fx_clean\"]\n","    taxi_info = date_info[\"silver_taxi_daily\"]\n","    \n","    try:\n","        taxi_start = str(taxi_info[\"min_date\"])\n","        taxi_end = str(taxi_info[\"max_date\"])\n","        fx_start = str(fx_info[\"min_date\"])\n","        fx_end = str(fx_info[\"max_date\"])\n","        \n","        print(f\"   Taxi period: {taxi_start} to {taxi_end}\")\n","        print(f\"   FX period: {fx_start} to {fx_end}\")\n","        \n","        # Check specific coverage\n","        taxi_days = spark.table(\"silver_taxi_daily\").select(\"pickup_date\").distinct()\n","        fx_dates = spark.table(\"silver_fx_clean\").select(\"date\").distinct()\n","        \n","        fx_coverage = taxi_days.join(fx_dates, taxi_days.pickup_date == fx_dates.date).count()\n","        total_taxi_days = taxi_days.count()\n","        \n","        if fx_coverage > 0:\n","            print(f\"   ‚úÖ Taxi days with FX rates: {fx_coverage}/{total_taxi_days} ({fx_coverage/total_taxi_days*100:.1f}%)\")\n","            \n","            # Show sample with FX rates\n","            print(f\"   Sample taxi days with FX rates:\")\n","            taxi_with_fx = spark.table(\"silver_taxi_daily\").join(\n","                spark.table(\"silver_fx_clean\"),\n","                col(\"pickup_date\") == col(\"date\"),\n","                \"inner\"\n","            ).limit(5)\n","            \n","            taxi_with_fx.select(\"pickup_date\", \"trip_count\", \"total_revenue_usd\", \"usd_eur_rate\").show()\n","        else:\n","            print(f\"   ‚ö†Ô∏è  No FX rates available for taxi dates\")\n","            \n","    except Exception as e:\n","        print(f\"   Error checking FX coverage: {str(e)[:100]}\")\n","\n","# ============================================================================\n","# 3. ANALYTICAL QUESTION EXPLORATION\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"3Ô∏è‚É£ ANALYTICAL CAPABILITIES - REALITY CHECK\")\n","print(\"=\"*80)\n","\n","print(\"\\nüîç REALISTIC ANALYSIS POSSIBILITIES:\")\n","\n","# 1. Taxi patterns analysis\n","print(\"\\nüöï TAXI PATTERNS ANALYSIS:\")\n","try:\n","    taxi_daily = spark.table(\"silver_taxi_daily\")\n","    \n","    # Get Jan 2024 data (main taxi period)\n","    jan_2024 = taxi_daily.filter(col(\"pickup_date\").between(\"2024-01-01\", \"2024-01-31\"))\n","    jan_days = jan_2024.count()\n","    \n","    if jan_days > 0:\n","        jan_trips = jan_2024.select(sum(\"trip_count\")).collect()[0][0] or 0\n","        jan_revenue = jan_2024.select(sum(\"total_revenue_usd\")).collect()[0][0] or 0\n","        \n","        print(f\"   January 2024: {jan_days} days, {jan_trips:,} trips, ${jan_revenue:,.2f} revenue\")\n","        \n","        # Show daily pattern\n","        print(f\"   Daily pattern (first 7 days):\")\n","        jan_2024.orderBy(\"pickup_date\").limit(7).show()\n","    else:\n","        print(f\"   No January 2024 data found\")\n","        \n","    # Overall stats\n","    total_trips = taxi_daily.select(sum(\"trip_count\")).collect()[0][0] or 0\n","    total_revenue = taxi_daily.select(sum(\"total_revenue_usd\")).collect()[0][0] or 0\n","    print(f\"\\n   Total in dataset: {total_trips:,} trips, ${total_revenue:,.2f} revenue\")\n","    \n","except Exception as e:\n","    print(f\"   Error: {str(e)[:100]}\")\n","\n","# 2. Air quality analysis\n","print(\"\\nüå´Ô∏è AIR QUALITY ANALYSIS:\")\n","try:\n","    air_daily = spark.table(\"silver_air_quality_daily\")\n","    \n","    # Check data completeness\n","    pollutants = ['pm25', 'no2', 'o3', 'pm10']\n","    print(f\"   Data completeness by pollutant:\")\n","    \n","    for pollutant in pollutants:\n","        col_name = f'avg_{pollutant}'\n","        if col_name in air_daily.columns:\n","            has_data = air_daily.filter(col(col_name).isNotNull()).count()\n","            total = air_daily.count()\n","            pct = (has_data / total * 100) if total > 0 else 0\n","            print(f\"   {col_name.upper():20} {has_data:>4}/{total} days ({pct:.1f}%)\")\n","    \n","    # Check for Jan 2024 air quality\n","    jan_air = air_daily.filter(col(\"measurement_date\").between(\"2024-01-01\", \"2024-01-31\"))\n","    jan_air_days = jan_air.count()\n","    print(f\"\\n   January 2024 air quality days: {jan_air_days}\")\n","    \n","    if jan_air_days > 0:\n","        print(f\"   Sample Jan 2024 air quality data:\")\n","        jan_air.select(\"measurement_date\", \"avg_pm25\", \"avg_no2\", \"avg_o3\").limit(3).show()\n","        \n","except Exception as e:\n","    print(f\"   Error: {str(e)[:100]}\")\n","\n","# 3. Combined analysis potential\n","print(\"\\nüîó COMBINED ANALYSIS POTENTIAL:\")\n","try:\n","    # Find dates with BOTH taxi and air quality in Jan 2024\n","    jan_taxi_dates = spark.table(\"silver_taxi_daily\").filter(\n","        col(\"pickup_date\").between(\"2024-01-01\", \"2024-01-31\")\n","    ).select(\"pickup_date\").distinct()\n","    \n","    jan_air_dates = spark.table(\"silver_air_quality_daily\").filter(\n","        col(\"measurement_date\").between(\"2024-01-01\", \"2024-01-31\")\n","    ).select(\"measurement_date\").distinct()\n","    \n","    jan_overlap = jan_taxi_dates.join(\n","        jan_air_dates, \n","        jan_taxi_dates.pickup_date == jan_air_dates.measurement_date\n","    ).count()\n","    \n","    print(f\"   January 2024 days with BOTH taxi and air data: {jan_overlap}\")\n","    \n","    if jan_overlap > 0:\n","        print(f\"   ‚úÖ CAN CORRELATE taxi trips vs pollution for {jan_overlap} days in Jan 2024\")\n","        \n","        # Show example correlation\n","        combined = spark.table(\"silver_taxi_daily\").alias(\"taxi\").join(\n","            spark.table(\"silver_air_quality_daily\").alias(\"air\"),\n","            col(\"taxi.pickup_date\") == col(\"air.measurement_date\")\n","        ).filter(\n","            col(\"taxi.pickup_date\").between(\"2024-01-01\", \"2024-01-31\")\n","        ).select(\n","            col(\"taxi.pickup_date\").alias(\"date\"), \n","            \"trip_count\",\n","            \"total_revenue_usd\",\n","            \"avg_pm25\",\n","            \"avg_no2\"\n","        ).limit(5)\n","        \n","        print(f\"   Example correlation data:\")\n","        combined.show()\n","    else:\n","        print(f\"   ‚ö†Ô∏è  No overlapping days in January 2024 for correlation\")\n","        \n","except Exception as e:\n","    print(f\"   Error: {str(e)[:100]}\")\n","\n","# ============================================================================\n","# 4. TEST JOIN CAPABILITIES\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"4Ô∏è‚É£ TESTING JOIN CAPABILITIES\")\n","print(\"=\"*80)\n","\n","# Test 1: Taxi + Air Quality Join\n","print(\"\\nüîó TEST 1: Taxi Daily + Air Quality Join\")\n","try:\n","    taxi_daily = spark.table(\"silver_taxi_daily\")\n","    air_daily = spark.table(\"silver_air_quality_daily\")\n","    \n","    # Find overlapping dates\n","    join_result = taxi_daily.join(\n","        air_daily, \n","        taxi_daily.pickup_date == air_daily.measurement_date,\n","        \"inner\"\n","    )\n","    \n","    join_count = join_result.count()\n","    if join_count > 0:\n","        print(f\"   ‚úÖ JOIN WORKS! Found {join_count:,} overlapping records\")\n","        print(f\"   Sample joined data (first 3 records):\")\n","        join_result.select(\n","            \"pickup_date\", \n","            \"trip_count\", \n","            \"total_revenue_usd\",\n","            \"avg_pm25\",\n","            \"avg_no2\"\n","        ).limit(3).show()\n","    else:\n","        print(f\"   ‚ö†Ô∏è  No overlapping dates found for join\")\n","        \n","except Exception as e:\n","    print(f\"   ‚ùå Join error: {str(e)[:100]}\")\n","\n","# Test 2: Taxi + FX Join\n","print(\"\\nüí± TEST 2: Taxi Daily + FX Rates Join\")\n","try:\n","    taxi_daily = spark.table(\"silver_taxi_daily\")\n","    fx = spark.table(\"silver_fx_clean\")\n","    \n","    # Check FX date column name\n","    fx_date_col = None\n","    for col in fx.columns:\n","        if \"date\" in col.lower():\n","            fx_date_col = col\n","            break\n","    \n","    if fx_date_col:\n","        join_sample = taxi_daily.join(\n","            fx, \n","            taxi_daily.pickup_date == fx[f\"{fx_date_col}\"],\n","            \"left\"\n","        ).limit(5)\n","        \n","        print(f\"   Using FX date column: {fx_date_col}\")\n","        print(f\"   Sample with FX rates:\")\n","        join_sample.select(\n","            \"pickup_date\", \n","            \"total_revenue_usd\",\n","            fx_date_col,\n","            \"usd_eur_rate\"\n","        ).show()\n","        \n","        # Check how many taxi days have FX rates\n","        with_fx = taxi_daily.join(\n","            fx, \n","            taxi_daily.pickup_date == fx[f\"{fx_date_col}\"],\n","            \"inner\"\n","        ).count()\n","        \n","        total_taxi_days = taxi_daily.count()\n","        print(f\"   Taxi days with FX rates: {with_fx}/{total_taxi_days} ({with_fx/total_taxi_days*100:.1f}%)\")\n","        \n","except Exception as e:\n","    print(f\"   ‚ùå Join error: {str(e)[:100]}\")\n","\n","# Test 3: Taxi Clean + Zones Join\n","print(\"\\nüó∫Ô∏è TEST 3: Taxi Clean + Zones Join\")\n","try:\n","    taxi_clean = spark.table(\"silver_taxi_clean\")\n","    zones = spark.table(\"dim_zones\")\n","    \n","    # Test pickup zone join\n","    pickup_join = taxi_clean.join(\n","        zones,\n","        taxi_clean.pickup_zone == zones.zone_id,\n","        \"left\"\n","    ).limit(5)\n","    \n","    print(f\"   Pickup zone join test:\")\n","    pickup_join.select(\n","        \"pickup_time\",\n","        \"pickup_zone\",\n","        \"zone_name\",\n","        \"zone_type\"\n","    ).show()\n","    \n","except Exception as e:\n","    print(f\"   ‚ùå Join error: {str(e)[:100]}\")\n","\n","# ============================================================================\n","# 5. DATA QUALITY ASSESSMENT\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"5Ô∏è‚É£ DATA QUALITY ASSESSMENT\")\n","print(\"=\"*80)\n","\n","print(\"\"\"\n","üìä DATA QUALITY SUMMARY:\n","\n","‚úÖ STRENGTHS:\n","‚Ä¢ Taxi data: 2.7M trips, good structure, Jan 2024 focus\n","‚Ä¢ Air quality: Multiple pollutants, daily aggregates\n","‚Ä¢ Dimensions: Date and zones available (514 zones)\n","‚Ä¢ FX rates: Historical rates from 1999 to present\n","‚Ä¢ Detailed taxi data: Hourly breakdown available\n","\n","‚ö†Ô∏è LIMITATIONS:\n","‚Ä¢ Limited date overlap between datasets\n","‚Ä¢ Air quality data has gaps (some pollutants missing)\n","‚Ä¢ No geographic coordinates for zones\n","‚Ä¢ GDP data very limited (placeholder for USA only)\n","\n","üéØ DATA COMPLETENESS:\n","1. Taxi Data: EXCELLENT (2.7M records, Jan 2024 focus)\n","2. Air Quality: GOOD but inconsistent (sparse measurements)\n","3. FX Rates: EXCELLENT (1999-present, daily rates)\n","4. Dimensions: GOOD (Date, Zones available)\n","5. GDP Data: LIMITED (placeholder only)\n","\n","üí° KEY INSIGHTS:\n","‚Ä¢ Strong foundation for taxi analytics\n","‚Ä¢ Good environmental data for trend analysis\n","‚Ä¢ FX data enables currency conversion\n","‚Ä¢ Limited correlation potential but methodology can be demonstrated\n","\"\"\")\n","\n","# ============================================================================\n","# 6. PRACTICAL RECOMMENDATIONS FOR GOLD LAYER\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"üéØ PRACTICAL RECOMMENDATIONS FOR GOLD LAYER\")\n","print(\"=\"*80)\n","\n","print(\"\"\"\n","üìä WHAT YOU CAN REALISTICALLY ACHIEVE:\n","\n","‚úÖ DEFINITELY POSSIBLE:\n","1. Taxi mobility analysis (January 2024 focus)\n","   ‚Ä¢ Daily trip patterns and trends\n","   ‚Ä¢ Revenue analysis by day/hour  \n","   ‚Ä¢ Zone popularity analysis (514 zones)\n","   ‚Ä¢ Passenger count distribution\n","   ‚Ä¢ Trip duration analysis\n","\n","2. Air quality trend analysis\n","   ‚Ä¢ Pollution patterns over available dates\n","   ‚Ä¢ Pollutant correlations (when data exists)\n","   ‚Ä¢ Daily/weekly patterns\n","   ‚Ä¢ Data quality handling demonstration\n","\n","3. Economic integration\n","   ‚Ä¢ Convert USD revenue to EUR using FX rates\n","   ‚Ä¢ Demonstrate exchange rate impact\n","   ‚Ä¢ Show multi-currency reporting\n","\n","‚ö†Ô∏è LIMITED BUT POSSIBLE:\n","4. Taxi vs Air Quality correlation\n","   ‚Ä¢ Limited overlapping days\n","   ‚Ä¢ Can demonstrate methodology\n","   ‚Ä¢ Show what WOULD be possible with better alignment\n","   ‚Ä¢ Create example visualizations\n","\n","üìå GOLD LAYER STRATEGY:\n","\n","FOCUS AREA 1: TAXI ANALYTICS (Strong Foundation)\n","  ‚Ä¢ Build comprehensive taxi fact tables\n","  ‚Ä¢ Create taxi-specific dimensions\n","  ‚Ä¢ Develop rich mobility dashboards\n","\n","FOCUS AREA 2: ENVIRONMENTAL ANALYTICS (Good Data)  \n","  ‚Ä¢ Build pollution fact tables\n","  ‚Ä¢ Create pollutant dimensions\n","  ‚Ä¢ Demonstrate data quality handling\n","\n","FOCUS AREA 3: ECONOMIC ANALYTICS (Excellent FX Data)\n","  ‚Ä¢ Currency conversion capabilities\n","  ‚Ä¢ Multi-currency reporting\n","  ‚Ä¢ Economic impact demonstration\n","\n","FOCUS AREA 4: INTEGRATED ANALYSIS (Methodology Focus)\n","  ‚Ä¢ Demonstrate JOIN techniques\n","  ‚Ä¢ Show correlation methodology\n","  ‚Ä¢ Document real-world data challenges\n","\"\"\")\n","\n","# ============================================================================\n","# 7. IMMEDIATE NEXT STEPS\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ IMMEDIATE NEXT STEPS\")\n","print(\"=\"*80)\n","\n","print(\"\"\"\n","üìå CREATE GOLD LAYER WITH THESE PRIORITIES:\n","\n","PHASE 1: BUILD FOUNDATION (Week 1)\n","1. FactTaxiDaily - Primary fact table\n","   ‚Ä¢ From silver_taxi_daily\n","   ‚Ä¢ Join with DimDate, DimZone\n","   ‚Ä¢ Add derived metrics\n","   \n","2. DimDateEnhanced - Enhanced date dimension\n","   ‚Ä¢ From dim_date_clean\n","   ‚Ä¢ Add fiscal periods, holidays, seasons\n","   ‚Ä¢ Add day characteristics\n","   \n","3. DimZoneEnhanced - Enhanced zone dimension\n","   ‚Ä¢ From dim_zones  \n","   ‚Ä¢ Add zone hierarchy if possible\n","   ‚Ä¢ Add geographic metadata placeholder\n","\n","PHASE 2: ENVIRONMENTAL DATA (Week 1)\n","4. FactAirQualityDaily - Environmental fact table\n","   ‚Ä¢ From silver_air_quality_daily\n","   ‚Ä¢ Professional NULL handling\n","   ‚Ä¢ Data quality flags\n","   \n","5. DimPollutant - Pollutant dimension\n","   ‚Ä¢ PM2.5, NO2, O3, PM10 characteristics\n","   ‚Ä¢ Health impact categories\n","   ‚Ä¢ Regulatory thresholds\n","\n","PHASE 3: ECONOMIC INTEGRATION (Week 2)  \n","6. DimCurrency - Currency dimension\n","   ‚Ä¢ From silver_fx_clean\n","   ‚Ä¢ USD/EUR exchange rates\n","   ‚Ä¢ Historical rate tracking\n","   \n","7. FactRevenueEUR - Currency converted revenue\n","   ‚Ä¢ Taxi revenue converted to EUR\n","   ‚Ä¢ Demonstrate currency impact\n","   ‚Ä¢ Multi-currency reporting\n","\n","PHASE 4: ADVANCED ANALYTICS (Week 2)\n","8. FactTaxiHourly - Granular analysis\n","   ‚Ä¢ From silver_taxi_clean\n","   ‚Ä¢ Hourly patterns\n","   ‚Ä¢ Time-based analytics\n","   \n","9. BridgeTaxiAirQuality - Correlation bridge\n","   ‚Ä¢ For overlapping days\n","   ‚Ä¢ Correlation methodology\n","   ‚Ä¢ Example analysis\n","\n","üéØ SUCCESS CRITERIA:\n","‚Ä¢ Working star schema in Fabric Warehouse ‚úì\n","‚Ä¢ Power BI dataset with all facts/dimensions ‚úì  \n","‚Ä¢ 3 comprehensive dashboards ‚úì\n","‚Ä¢ Complete documentation of data pipeline ‚úì\n","‚Ä¢ Demonstration of real-world data challenges ‚úì\n","‚Ä¢ Methodology for handling limited data ‚úì\n","\"\"\")\n","\n","# ============================================================================\n","# 8. SUMMARY METRICS\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"üìà SUMMARY METRICS\")\n","print(\"=\"*80)\n","\n","# Calculate key metrics\n","try:\n","    # Taxi metrics\n","    taxi_daily = spark.table(\"silver_taxi_daily\")\n","    total_taxi_days = taxi_daily.count()\n","    total_taxi_trips = taxi_daily.select(sum(\"trip_count\")).collect()[0][0] or 0\n","    total_taxi_revenue = taxi_daily.select(sum(\"total_revenue_usd\")).collect()[0][0] or 0\n","    \n","    # Air quality metrics\n","    air_daily = spark.table(\"silver_air_quality_daily\")\n","    total_air_days = air_daily.count()\n","    air_days_with_pm25 = air_daily.filter(col(\"avg_pm25\").isNotNull()).count()\n","    \n","    # Zone metrics\n","    zones = spark.table(\"dim_zones\")\n","    total_zones = zones.count()\n","    pickup_zones = zones.filter(col(\"zone_type\") == \"Pickup\").count()\n","    \n","    print(f\"\"\"\n","üìä KEY METRICS:\n","‚Ä¢ Taxi Data: {total_taxi_days:,} days, {total_taxi_trips:,} trips, ${total_taxi_revenue:,.2f} revenue\n","‚Ä¢ Air Quality: {total_air_days:,} days ({air_days_with_pm25:,} with PM2.5 data)\n","‚Ä¢ Zones: {total_zones:,} total zones ({pickup_zones:,} pickup zones)\n","‚Ä¢ FX Rates: 1999 to present (daily rates)\n","‚Ä¢ Date Dimension: 2020-2024 ({spark.table('dim_date_clean').count():,} days)\n","\"\"\")\n","    \n","except Exception as e:\n","    print(f\"Error calculating summary metrics: {str(e)[:100]}\")\n","\n","print(f\"\\n‚úÖ Exploratory analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","print(\"=\"*80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"bce670b9-bbdd-4176-af4c-daf4090bee40","normalized_state":"finished","queued_time":"2025-12-19T14:34:18.7683639Z","session_start_time":null,"execution_start_time":"2025-12-19T14:34:18.7702934Z","execution_finish_time":"2025-12-19T14:35:17.318339Z","parent_msg_id":"b9c18bad-b3da-40dd-8e02-7f875ca8a54b"},"text/plain":"StatementMeta(, bce670b9-bbdd-4176-af4c-daf4090bee40, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["================================================================================\nüîç SILVER LAYER EXPLORATORY ANALYSIS\n================================================================================\nAnalysis started: 2025-12-19 14:34:18\n\n1Ô∏è‚É£ TABLE STRUCTURE ANALYSIS\n================================================================================\nAnalyzing 11 active tables...\n\nüìä silver_taxi_clean:\n   Rows: 2,723,560\n   Columns: 11\n   First 5 columns: ['pickup_time', 'dropoff_time', 'passenger_count', 'distance_miles', 'pickup_zone']\n   Date columns: ['pickup_time', 'dropoff_time', 'pickup_date']\n   Date range: 2002-12-31 22:59:39 to 2024-02-01 00:01:15\n   Numeric columns: 8 (e.g., ['passenger_count', 'distance_miles', 'pickup_zone'])\n   Sample data:\n-RECORD 0-------------------------------\n pickup_time      | 2024-01-24 15:17:12 \n dropoff_time     | 2024-01-24 15:34:53 \n passenger_count  | 1                   \n distance_miles   | 3.33                \n pickup_zone      | 239                 \n dropoff_zone     | 246                 \n fare_usd         | 20.5                \n total_usd        | 27.5                \n pickup_date      | 2024-01-24          \n pickup_hour      | 15                  \n duration_minutes | 17.7                \n-RECORD 1-------------------------------\n pickup_time      | 2024-01-24 15:52:24 \n dropoff_time     | 2024-01-24 16:01:39 \n passenger_count  | 1                   \n distance_miles   | 1.61                \n pickup_zone      | 234                 \n dropoff_zone     | 249                 \n fare_usd         | 10.7                \n total_usd        | 18.37               \n pickup_date      | 2024-01-24          \n pickup_hour      | 15                  \n duration_minutes | 9.3                 \n-RECORD 2-------------------------------\n pickup_time      | 2024-01-24 15:08:55 \n dropoff_time     | 2024-01-24 15:31:35 \n passenger_count  | 1                   \n distance_miles   | 4.38                \n pickup_zone      | 88                  \n dropoff_zone     | 211                 \n fare_usd         | 25.4                \n total_usd        | 35.28               \n pickup_date      | 2024-01-24          \n pickup_hour      | 15                  \n duration_minutes | 22.7                \n\n\nüìä silver_taxi_daily:\n   Rows: 35\n   Columns: 5\n   First 5 columns: ['pickup_date', 'trip_count', 'total_revenue_usd', 'avg_fare_usd', 'avg_duration_min']\n   Date columns: ['pickup_date']\n   Date range: 2002-12-31 to 2024-02-01\n   Numeric columns: 4 (e.g., ['trip_count', 'total_revenue_usd', 'avg_fare_usd'])\n   Sample data:\n-RECORD 0-------------------------------\n pickup_date       | 2002-12-31         \n trip_count        | 1                  \n total_revenue_usd | 6.5                \n avg_fare_usd      | 6.5                \n avg_duration_min  | 6.0                \n-RECORD 1-------------------------------\n pickup_date       | 2009-01-01         \n trip_count        | 3                  \n total_revenue_usd | 100.0              \n avg_fare_usd      | 33.333333333333336 \n avg_duration_min  | 27.633333333333336 \n-RECORD 2-------------------------------\n pickup_date       | 2023-12-31         \n trip_count        | 10                 \n total_revenue_usd | 144.1              \n avg_fare_usd      | 14.41              \n avg_duration_min  | 10.16              \n\n\nüìä silver_air_quality_daily:\n   Rows: 314\n   Columns: 9\n   First 5 columns: ['measurement_date', 'avg_pm25', 'pm25_measurements', 'avg_no2', 'no2_measurements']\n   Date columns: ['measurement_date']\n   Date range: 2016-03-23 to 2025-12-16\n   Numeric columns: 2 (e.g., ['avg_pm25', 'pm25_measurements'])\n   Sample data:\n-RECORD 0--------------------------------\n measurement_date  | 2023-06-22          \n avg_pm25          | 0.012               \n pm25_measurements | 1                   \n avg_no2           | NULL                \n no2_measurements  | NULL                \n avg_o3            | NULL                \n o3_measurements   | NULL                \n avg_pm10          | NULL                \n pm10_measurements | NULL                \n-RECORD 1--------------------------------\n measurement_date  | 2019-11-21          \n avg_pm25          | 13.0                \n pm25_measurements | 1                   \n avg_no2           | NULL                \n no2_measurements  | NULL                \n avg_o3            | NULL                \n o3_measurements   | NULL                \n avg_pm10          | NULL                \n pm10_measurements | NULL                \n-RECORD 2--------------------------------\n measurement_date  | 2024-11-23          \n avg_pm25          | 0.06666666766007741 \n pm25_measurements | 1                   \n avg_no2           | NULL                \n no2_measurements  | NULL                \n avg_o3            | NULL                \n o3_measurements   | NULL                \n avg_pm10          | NULL                \n pm10_measurements | NULL                \n\n\nüìä dim_date_clean:\n   Rows: 1,825\n   Columns: 7\n   First 5 columns: ['full_date', 'year', 'month', 'day', 'day_of_week']\n   Date columns: ['full_date']\n   Date range: 2020-01-01 to 2024-12-29\n   Numeric columns: 5 (e.g., ['year', 'month', 'day'])\n   Sample data:\n-RECORD 0-----------------\n full_date   | 2020-08-16 \n year        | 2020       \n month       | 8          \n day         | 16         \n day_of_week | 1          \n day_name    | Sunday     \n is_weekend  | 1          \n-RECORD 1-----------------\n full_date   | 2020-08-17 \n year        | 2020       \n month       | 8          \n day         | 17         \n day_of_week | 2          \n day_name    | Monday     \n is_weekend  | 0          \n-RECORD 2-----------------\n full_date   | 2020-08-18 \n year        | 2020       \n month       | 8          \n day         | 18         \n day_of_week | 3          \n day_name    | Tuesday    \n is_weekend  | 0          \n\n\nüìä dim_zones:\n   Rows: 514\n   Columns: 3\n   First 5 columns: ['zone_id', 'zone_type', 'zone_name']\n   Numeric columns: 1 (e.g., ['zone_id'])\n   Sample data:\n-RECORD 0-------------\n zone_id   | 19       \n zone_type | Pickup   \n zone_name | Zone 19  \n-RECORD 1-------------\n zone_id   | 137      \n zone_type | Pickup   \n zone_name | Zone 137 \n-RECORD 2-------------\n zone_id   | 18       \n zone_type | Pickup   \n zone_name | Zone 18  \n\n\nüìä silver_fx_clean:\n   Rows: 6,904\n   Columns: 2\n   First 5 columns: ['date', 'usd_eur_rate']\n   Date columns: ['date']\n   Date range: 1999-01-04 to 2025-12-16\n   Numeric columns: 1 (e.g., ['usd_eur_rate'])\n   Sample data:\n-RECORD 0------------------\n date         | 1999-01-04 \n usd_eur_rate | 1.1789     \n-RECORD 1------------------\n date         | 1999-01-05 \n usd_eur_rate | 1.179      \n-RECORD 2------------------\n date         | 1999-01-06 \n usd_eur_rate | 1.1743     \n\n\nüìä silver_gdp_clean:\n   Rows: 3\n   Columns: 4\n   First 5 columns: ['country_code', 'country_name', 'year', 'gdp_usd']\n   Numeric columns: 1 (e.g., ['gdp_usd'])\n   Sample data:\n-RECORD 0----------------------\n country_code | USA            \n country_name | United States  \n year         | 2022           \n gdp_usd      | 23300000000000 \n-RECORD 1----------------------\n country_code | USA            \n country_name | United States  \n year         | 2021           \n gdp_usd      | 23000000000000 \n-RECORD 2----------------------\n country_code | USA            \n country_name | United States  \n year         | 2023           \n gdp_usd      | 25400000000000 \n\n\nüìä silver_pm25_std:\n   Rows: 500\n   Columns: 6\n   First 5 columns: ['measurement_time', 'measurement_date', 'pm25_value', 'city_name', 'location_name']\n   Date columns: ['measurement_time', 'measurement_date']\n   Date range: 2017-04-28 11:00:00 to 2025-12-16 22:13:00\n   Numeric columns: 1 (e.g., ['pm25_value'])\n   Sample data:\n-RECORD 0-------------------------------\n measurement_time | 2025-12-16 22:00:00 \n measurement_date | 2025-12-16          \n pm25_value       | 14.630357123556593  \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM25                \n-RECORD 1-------------------------------\n measurement_time | 2025-12-16 22:00:00 \n measurement_date | 2025-12-16          \n pm25_value       | 5.35227277062156    \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM25                \n-RECORD 2-------------------------------\n measurement_time | 2025-12-16 21:02:17 \n measurement_date | 2025-12-16          \n pm25_value       | 6.16                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM25                \n\n\nüìä silver_no2_std:\n   Rows: 500\n   Columns: 6\n   First 5 columns: ['measurement_time', 'measurement_date', 'no2_value', 'city_name', 'location_name']\n   Date columns: ['measurement_time', 'measurement_date']\n   Date range: 2016-04-27 15:00:00 to 2025-12-16 22:00:00\n   Numeric columns: 1 (e.g., ['no2_value'])\n   Sample data:\n-RECORD 0-------------------------------\n measurement_time | 2025-12-16 20:00:00 \n measurement_date | 2025-12-16          \n no2_value        | 1.0                 \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | NO2                 \n-RECORD 1-------------------------------\n measurement_time | 2025-12-16 20:00:00 \n measurement_date | 2025-12-16          \n no2_value        | -1.0                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | NO2                 \n-RECORD 2-------------------------------\n measurement_time | 2025-12-15 01:00:00 \n measurement_date | 2025-12-15          \n no2_value        | 2.7                 \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | NO2                 \n\n\nüìä silver_o3_std:\n   Rows: 500\n   Columns: 6\n   First 5 columns: ['measurement_time', 'measurement_date', 'o3_value', 'city_name', 'location_name']\n   Date columns: ['measurement_time', 'measurement_date']\n   Date range: 2016-06-24 10:45:00 to 2025-12-16 22:00:00\n   Numeric columns: 1 (e.g., ['o3_value'])\n   Sample data:\n-RECORD 0-------------------------------\n measurement_time | 2025-12-16 21:00:00 \n measurement_date | 2025-12-16          \n o3_value         | 98.0                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | O3                  \n-RECORD 1-------------------------------\n measurement_time | 2025-12-15 01:00:00 \n measurement_date | 2025-12-15          \n o3_value         | 51.9                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | O3                  \n-RECORD 2-------------------------------\n measurement_time | 2025-12-16 21:00:00 \n measurement_date | 2025-12-16          \n o3_value         | 36.0                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | O3                  \n\n\nüìä silver_pm10_std:\n   Rows: 500\n   Columns: 6\n   First 5 columns: ['measurement_time', 'measurement_date', 'pm10_value', 'city_name', 'location_name']\n   Date columns: ['measurement_time', 'measurement_date']\n   Date range: 2016-03-23 14:00:00 to 2025-12-16 22:13:00\n   Numeric columns: 1 (e.g., ['pm10_value'])\n   Sample data:\n-RECORD 0-------------------------------\n measurement_time | 2024-03-10 18:00:00 \n measurement_date | 2024-03-10          \n pm10_value       | 18.76785707473755   \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM10                \n-RECORD 1-------------------------------\n measurement_time | 2024-11-27 11:00:00 \n measurement_date | 2024-11-27          \n pm10_value       | 1.130208323399226   \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM10                \n-RECORD 2-------------------------------\n measurement_time | 2025-12-15 10:00:00 \n measurement_date | 2025-12-15          \n pm10_value       | 21.0                \n city_name        | New York            \n location_name    | NYC                 \n pollutant        | PM10                \n\n\n================================================================================\n2Ô∏è‚É£ DATE ALIGNMENT ANALYSIS\n================================================================================\n\nüîó POTENTIAL JOIN POINTS:\n   Taxi dates: 2002-12-31 to 2024-02-01\n   Air dates: 2016-03-23 to 2025-12-16\n   ‚úÖ Taxi ‚Üî Air Quality overlap: 2024-01-02 to 2024-01-29\n   Days with BOTH taxi and air data: 5\n   Sample overlapping dates:\n+-----------+----------------+\n|pickup_date|measurement_date|\n+-----------+----------------+\n| 2024-01-02|      2024-01-02|\n| 2024-01-28|      2024-01-28|\n| 2024-01-03|      2024-01-03|\n| 2024-01-08|      2024-01-08|\n| 2024-01-29|      2024-01-29|\n+-----------+----------------+\n\n\nüí± FX ‚Üî Taxi Date Alignment:\n   Taxi period: 2002-12-31 to 2024-02-01\n   FX period: 1999-01-04 to 2025-12-16\n   ‚úÖ Taxi days with FX rates: 24/35 (68.6%)\n   Sample taxi days with FX rates:\n+-----------+----------+------------------+------------+\n|pickup_date|trip_count| total_revenue_usd|usd_eur_rate|\n+-----------+----------+------------------+------------+\n| 2002-12-31|         1|               6.5|      1.0487|\n| 2024-01-02|     70481| 1506096.000000011|      1.0956|\n| 2024-01-03|     77433|1551728.6500000043|      1.0919|\n| 2024-01-04|     96778|1811345.2600000156|      1.0953|\n| 2024-01-05|     96359|1743097.7999999814|      1.0921|\n+-----------+----------+------------------+------------+\n\n\n================================================================================\n3Ô∏è‚É£ ANALYTICAL CAPABILITIES - REALITY CHECK\n================================================================================\n\nüîç REALISTIC ANALYSIS POSSIBILITIES:\n\nüöï TAXI PATTERNS ANALYSIS:\n   January 2024: 31 days, 2,723,543 trips, $50,219,866.99 revenue\n   Daily pattern (first 7 days):\n+-----------+----------+------------------+------------------+------------------+\n|pickup_date|trip_count| total_revenue_usd|      avg_fare_usd|  avg_duration_min|\n+-----------+----------+------------------+------------------+------------------+\n| 2024-01-01|     67396|1480839.7400000114|21.972220013057324|16.824410944269456|\n| 2024-01-02|     70481| 1506096.000000011| 21.36882280330885|17.081961095898134|\n| 2024-01-03|     77433|1551728.6500000043|20.039629744424268|16.681713223044408|\n| 2024-01-04|     96778|1811345.2600000156|  18.7164981710721|16.135865589286542|\n| 2024-01-05|     96359|1743097.7999999814|18.089621104411435|15.450919997094173|\n| 2024-01-06|     88623|1561321.3900000202| 17.61756417634271| 14.71942497997141|\n| 2024-01-07|     62395|1240045.5599999933| 19.87411747736186|14.055068515105377|\n+-----------+----------+------------------+------------------+------------------+\n\n\n   Total in dataset: 2,723,560 trips, $50,220,175.59 revenue\n\nüå´Ô∏è AIR QUALITY ANALYSIS:\n   Data completeness by pollutant:\n   AVG_PM25              111/314 days (35.4%)\n   AVG_NO2               109/314 days (34.7%)\n   AVG_O3                 98/314 days (31.2%)\n   AVG_PM10              102/314 days (32.5%)\n\n   January 2024 air quality days: 5\n   Sample Jan 2024 air quality data:\n+----------------+------------------+-------------+------------------+\n|measurement_date|          avg_pm25|      avg_no2|            avg_o3|\n+----------------+------------------+-------------+------------------+\n|      2024-01-29|14.613448383333335|31.3439362225|42.039407498823536|\n|      2024-01-28|              NULL|        11.77|             45.24|\n|      2024-01-03|              NULL|          2.5|              NULL|\n+----------------+------------------+-------------+------------------+\n\n\nüîó COMBINED ANALYSIS POTENTIAL:\n   January 2024 days with BOTH taxi and air data: 5\n   ‚úÖ CAN CORRELATE taxi trips vs pollution for 5 days in Jan 2024\n   Example correlation data:\n+----------+----------+------------------+------------------+-------------+\n|      date|trip_count| total_revenue_usd|          avg_pm25|      avg_no2|\n+----------+----------+------------------+------------------+-------------+\n|2024-01-29|     78983| 1490557.760000003|14.613448383333335|31.3439362225|\n|2024-01-28|     82215|1507788.4400000123|              NULL|        11.77|\n|2024-01-03|     77433|1551728.6500000043|              NULL|          2.5|\n|2024-01-08|     74991|1429710.7200000172|              NULL|         30.4|\n|2024-01-02|     70481| 1506096.000000011|              NULL|         NULL|\n+----------+----------+------------------+------------------+-------------+\n\n\n================================================================================\n4Ô∏è‚É£ TESTING JOIN CAPABILITIES\n================================================================================\n\nüîó TEST 1: Taxi Daily + Air Quality Join\n   ‚úÖ JOIN WORKS! Found 5 overlapping records\n   Sample joined data (first 3 records):\n+-----------+----------+------------------+------------------+-------------+\n|pickup_date|trip_count| total_revenue_usd|          avg_pm25|      avg_no2|\n+-----------+----------+------------------+------------------+-------------+\n| 2024-01-29|     78983| 1490557.760000003|14.613448383333335|31.3439362225|\n| 2024-01-28|     82215|1507788.4400000123|              NULL|        11.77|\n| 2024-01-03|     77433|1551728.6500000043|              NULL|          2.5|\n+-----------+----------+------------------+------------------+-------------+\n\n\nüí± TEST 2: Taxi Daily + FX Rates Join\n   Using FX date column: date\n   Sample with FX rates:\n+-----------+------------------+----------+------------+\n|pickup_date| total_revenue_usd|      date|usd_eur_rate|\n+-----------+------------------+----------+------------+\n| 2002-12-31|               6.5|2002-12-31|      1.0487|\n| 2009-01-01|             100.0|      NULL|        NULL|\n| 2023-12-31|             144.1|      NULL|        NULL|\n| 2024-01-01|1480839.7400000114|      NULL|        NULL|\n| 2024-01-02| 1506096.000000011|2024-01-02|      1.0956|\n+-----------+------------------+----------+------------+\n\n   Taxi days with FX rates: 24/35 (68.6%)\n\nüó∫Ô∏è TEST 3: Taxi Clean + Zones Join\n   Pickup zone join test:\n+-------------------+-----------+---------+---------+\n|        pickup_time|pickup_zone|zone_name|zone_type|\n+-------------------+-----------+---------+---------+\n|2024-01-24 15:17:12|        239| Zone 239|  Dropoff|\n|2024-01-24 15:17:12|        239| Zone 239|   Pickup|\n|2024-01-24 15:52:24|        234| Zone 234|  Dropoff|\n|2024-01-24 15:52:24|        234| Zone 234|   Pickup|\n|2024-01-24 15:08:55|         88|  Zone 88|  Dropoff|\n+-------------------+-----------+---------+---------+\n\n\n================================================================================\n5Ô∏è‚É£ DATA QUALITY ASSESSMENT\n================================================================================\n\nüìä DATA QUALITY SUMMARY:\n\n‚úÖ STRENGTHS:\n‚Ä¢ Taxi data: 2.7M trips, good structure, Jan 2024 focus\n‚Ä¢ Air quality: Multiple pollutants, daily aggregates\n‚Ä¢ Dimensions: Date and zones available (514 zones)\n‚Ä¢ FX rates: Historical rates from 1999 to present\n‚Ä¢ Detailed taxi data: Hourly breakdown available\n\n‚ö†Ô∏è LIMITATIONS:\n‚Ä¢ Limited date overlap between datasets\n‚Ä¢ Air quality data has gaps (some pollutants missing)\n‚Ä¢ No geographic coordinates for zones\n‚Ä¢ GDP data very limited (placeholder for USA only)\n\nüéØ DATA COMPLETENESS:\n1. Taxi Data: EXCELLENT (2.7M records, Jan 2024 focus)\n2. Air Quality: GOOD but inconsistent (sparse measurements)\n3. FX Rates: EXCELLENT (1999-present, daily rates)\n4. Dimensions: GOOD (Date, Zones available)\n5. GDP Data: LIMITED (placeholder only)\n\nüí° KEY INSIGHTS:\n‚Ä¢ Strong foundation for taxi analytics\n‚Ä¢ Good environmental data for trend analysis\n‚Ä¢ FX data enables currency conversion\n‚Ä¢ Limited correlation potential but methodology can be demonstrated\n\n\n================================================================================\nüéØ PRACTICAL RECOMMENDATIONS FOR GOLD LAYER\n================================================================================\n\nüìä WHAT YOU CAN REALISTICALLY ACHIEVE:\n\n‚úÖ DEFINITELY POSSIBLE:\n1. Taxi mobility analysis (January 2024 focus)\n   ‚Ä¢ Daily trip patterns and trends\n   ‚Ä¢ Revenue analysis by day/hour  \n   ‚Ä¢ Zone popularity analysis (514 zones)\n   ‚Ä¢ Passenger count distribution\n   ‚Ä¢ Trip duration analysis\n\n2. Air quality trend analysis\n   ‚Ä¢ Pollution patterns over available dates\n   ‚Ä¢ Pollutant correlations (when data exists)\n   ‚Ä¢ Daily/weekly patterns\n   ‚Ä¢ Data quality handling demonstration\n\n3. Economic integration\n   ‚Ä¢ Convert USD revenue to EUR using FX rates\n   ‚Ä¢ Demonstrate exchange rate impact\n   ‚Ä¢ Show multi-currency reporting\n\n‚ö†Ô∏è LIMITED BUT POSSIBLE:\n4. Taxi vs Air Quality correlation\n   ‚Ä¢ Limited overlapping days\n   ‚Ä¢ Can demonstrate methodology\n   ‚Ä¢ Show what WOULD be possible with better alignment\n   ‚Ä¢ Create example visualizations\n\nüìå GOLD LAYER STRATEGY:\n\nFOCUS AREA 1: TAXI ANALYTICS (Strong Foundation)\n  ‚Ä¢ Build comprehensive taxi fact tables\n  ‚Ä¢ Create taxi-specific dimensions\n  ‚Ä¢ Develop rich mobility dashboards\n\nFOCUS AREA 2: ENVIRONMENTAL ANALYTICS (Good Data)  \n  ‚Ä¢ Build pollution fact tables\n  ‚Ä¢ Create pollutant dimensions\n  ‚Ä¢ Demonstrate data quality handling\n\nFOCUS AREA 3: ECONOMIC ANALYTICS (Excellent FX Data)\n  ‚Ä¢ Currency conversion capabilities\n  ‚Ä¢ Multi-currency reporting\n  ‚Ä¢ Economic impact demonstration\n\nFOCUS AREA 4: INTEGRATED ANALYSIS (Methodology Focus)\n  ‚Ä¢ Demonstrate JOIN techniques\n  ‚Ä¢ Show correlation methodology\n  ‚Ä¢ Document real-world data challenges\n\n\n================================================================================\nüöÄ IMMEDIATE NEXT STEPS\n================================================================================\n\nüìå CREATE GOLD LAYER WITH THESE PRIORITIES:\n\nPHASE 1: BUILD FOUNDATION (Week 1)\n1. FactTaxiDaily - Primary fact table\n   ‚Ä¢ From silver_taxi_daily\n   ‚Ä¢ Join with DimDate, DimZone\n   ‚Ä¢ Add derived metrics\n   \n2. DimDateEnhanced - Enhanced date dimension\n   ‚Ä¢ From dim_date_clean\n   ‚Ä¢ Add fiscal periods, holidays, seasons\n   ‚Ä¢ Add day characteristics\n   \n3. DimZoneEnhanced - Enhanced zone dimension\n   ‚Ä¢ From dim_zones  \n   ‚Ä¢ Add zone hierarchy if possible\n   ‚Ä¢ Add geographic metadata placeholder\n\nPHASE 2: ENVIRONMENTAL DATA (Week 1)\n4. FactAirQualityDaily - Environmental fact table\n   ‚Ä¢ From silver_air_quality_daily\n   ‚Ä¢ Professional NULL handling\n   ‚Ä¢ Data quality flags\n   \n5. DimPollutant - Pollutant dimension\n   ‚Ä¢ PM2.5, NO2, O3, PM10 characteristics\n   ‚Ä¢ Health impact categories\n   ‚Ä¢ Regulatory thresholds\n\nPHASE 3: ECONOMIC INTEGRATION (Week 2)  \n6. DimCurrency - Currency dimension\n   ‚Ä¢ From silver_fx_clean\n   ‚Ä¢ USD/EUR exchange rates\n   ‚Ä¢ Historical rate tracking\n   \n7. FactRevenueEUR - Currency converted revenue\n   ‚Ä¢ Taxi revenue converted to EUR\n   ‚Ä¢ Demonstrate currency impact\n   ‚Ä¢ Multi-currency reporting\n\nPHASE 4: ADVANCED ANALYTICS (Week 2)\n8. FactTaxiHourly - Granular analysis\n   ‚Ä¢ From silver_taxi_clean\n   ‚Ä¢ Hourly patterns\n   ‚Ä¢ Time-based analytics\n   \n9. BridgeTaxiAirQuality - Correlation bridge\n   ‚Ä¢ For overlapping days\n   ‚Ä¢ Correlation methodology\n   ‚Ä¢ Example analysis\n\nüéØ SUCCESS CRITERIA:\n‚Ä¢ Working star schema in Fabric Warehouse ‚úì\n‚Ä¢ Power BI dataset with all facts/dimensions ‚úì  \n‚Ä¢ 3 comprehensive dashboards ‚úì\n‚Ä¢ Complete documentation of data pipeline ‚úì\n‚Ä¢ Demonstration of real-world data challenges ‚úì\n‚Ä¢ Methodology for handling limited data ‚úì\n\n\n================================================================================\nüìà SUMMARY METRICS\n================================================================================\nError calculating summary metrics: 'str' object is not callable\n\n‚úÖ Exploratory analysis completed: 2025-12-19 14:35:15\n================================================================================\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b40bb14f-6c59-4782-8812-5365109d66eb"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7cdd5ef1-799a-43d7-933c-1cb089819985"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"43a87f10-dba3-40c6-bcad-e487dca16642"}],"default_lakehouse":"43a87f10-dba3-40c6-bcad-e487dca16642","default_lakehouse_name":"LH_Core","default_lakehouse_workspace_id":"1811eb14-437b-442d-8c65-60ad4b700adc"}}},"nbformat":4,"nbformat_minor":5}